{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyze wandb logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import pandas as pd\n",
    "\n",
    "# Run wandb login on the command line and paste in your API key\n",
    "api = wandb.Api()\n",
    "entity, project = \"mjavad\", \"tuh_sc_hps_pp3_cp\"  \n",
    "runs = api.runs(entity + \"/\" + project) \n",
    "\n",
    "summary_list, config_list, name_list = [], [], []\n",
    "for run in runs: \n",
    "    # .summary contains output keys/values for \n",
    "    # metrics such as accuracy.\n",
    "    #  We call ._json_dict to omit large files \n",
    "    summary_list.append(run.summary._json_dict)\n",
    "\n",
    "    # .config contains the hyperparameters.\n",
    "    #  We remove special values that start with _.\n",
    "    config_list.append(\n",
    "        {k: v for k,v in run.config.items()\n",
    "         if not k.startswith('_')})\n",
    "\n",
    "    # .name is the human-readable name of the run.\n",
    "    name_list.append(run.name)\n",
    "\n",
    "runs_df = pd.DataFrame({\n",
    "    \"summary\": summary_list,\n",
    "    \"config\": config_list,\n",
    "    \"name\": name_list\n",
    "    })\n",
    "\n",
    "runs_df.to_csv(\"project.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_runs = []\n",
    "ids_to_load_train = []\n",
    "valid_loss_wo = []\n",
    "valid_loss_w = []\n",
    "for run in runs:\n",
    "    if run.state == 'finished':\n",
    "        if 'TUH_deep4_hps_pp3_wN_woAug_' in run.name: #index2_number2700\n",
    "            all_runs.append(run)\n",
    "            valid_loss_wo.append(run.summary['valid_loss'])\n",
    "        elif 'TUH_deep4_hps_pp3_wN_wAug_' in run.name: #index2_number2700\n",
    "            all_runs.append(run)\n",
    "            valid_loss_w.append(run.summary['valid_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "print(np.mean(valid_loss_w), np.std(valid_loss_w))\n",
    "print(np.mean(valid_loss_wo),np.std(valid_loss_wo))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "rows = zip(valid_loss_w, valid_loss_wo)#, list3, list4, list5)\n",
    "\n",
    "# Open a csv file in write mode\n",
    "with open(\"data.csv\", \"w\") as f:\n",
    "    # Create a csv writer object\n",
    "    writer = csv.writer(f, quoting=csv.QUOTE_ALL)\n",
    "    writer.writerow(['valid_loss','w=0,wo=1'])\n",
    "    for row in valid_loss_w:\n",
    "        writer.writerow([row, '0'])\n",
    "    for row in valid_loss_wo:\n",
    "        writer.writerow([row, '1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plot loss vs data size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import pandas as pd\n",
    "# Run wandb login on the command line and paste in your API key\n",
    "api = wandb.Api()\n",
    "# entity, project = \"mjavad\", \"tuh_sc_hps_pp3_cp_wN\"  \n",
    "entity, project = \"mjavad\", \"tuh_scaling\"  \n",
    "\n",
    "runs = api.runs(entity + \"/\" + project) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_runs = []\n",
    "ids_to_load_train2 = []\n",
    "test_loss = []\n",
    "run_name = []\n",
    "pre_train = []\n",
    "test_b_acc =[]\n",
    "for run in runs:\n",
    "    if run.state == 'finished':\n",
    "        if 'NMT_deep4_hps_pp3_wN_wAug_WoPt81_index0' in run.name or 'NMT_deep4_hps_pp3_wN_wAug_WPt81_index9' in run.name: \n",
    "            try:\n",
    "                all_runs.append(run)\n",
    "                test_loss.append(run.summary['loss_nmt'])\n",
    "                test_b_acc.append(run.summary['b_acc_nmt'])\n",
    "                run_name.append(run.name)\n",
    "                pre_train.append(run.config[\"pre_trained\"])\n",
    "                ids_to_load_train2.append(run.config[\"ids_to_load_train2\"])\n",
    "            except:\n",
    "                print(run.name)\n",
    "                # run.delete()\n",
    "                \n",
    "        \n",
    "        # elif 'TUH_deep4_hps_pp3_wN_wAug_' in run.name: \n",
    "        #     all_runs.append(run)\n",
    "        #     valid_loss_w.append(run.summary['valid_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_runs = []\n",
    "ids_to_load_train2 = []\n",
    "test_loss = []\n",
    "run_name = []\n",
    "pre_train = []\n",
    "test_b_acc =[]\n",
    "for run in runs:\n",
    "    if run.state == 'finished': # NMT_deep4_hps_pp3_wN_wAug_WoPt81_28jul2045_index\n",
    "        if 'NMT_deep4_hps_pp3_woN_wAug_WoPt81_lr001_index' in run.name or 'NMT_deep4_hps_pp3_woN_wAug_WPt81_lr001_index' in run.name: \n",
    "            try:\n",
    "                all_runs.append(run)\n",
    "                test_loss.append(run.summary['loss_nmt'])\n",
    "                test_b_acc.append(run.summary['b_acc_nmt'])\n",
    "                run_name.append(run.name)\n",
    "                pre_train.append(run.config[\"pre_trained\"])\n",
    "                ids_to_load_train2.append(run.config[\"ids_to_load_train2\"])\n",
    "            except:\n",
    "                print(run.name)\n",
    "                # run.delete()\n",
    "                \n",
    "        \n",
    "        # elif 'TUH_deep4_hps_pp3_wN_wAug_' in run.name: \n",
    "        #     all_runs.append(run)\n",
    "        #     valid_loss_w.append(run.summary['valid_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'run_name': run_name, 'Pre-Train': pre_train,'ids_to_load_train2': ids_to_load_train2, 'test_loss': test_loss, 'test_b_acc': test_b_acc})\n",
    "# df.head()\n",
    "df = df.assign(run_name_tranc = lambda x: x.run_name.str.split('_').str[:-4].str.join('_'))\n",
    "df[\"ids_to_load_train2\"] = df[\"ids_to_load_train2\"].replace(0, 20)\n",
    "df.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# sns.lineplot(x=\"ids_to_load_train2\", y=\"test_loss\", hue='pre_train', data=df, errorbar=\"se\")\n",
    "fig = sns.lineplot(x=\"ids_to_load_train2\", y=\"test_b_acc\", hue='Pre-Train', data=df, errorbar=\"se\", err_style=\"bars\") #, None), orient='y')\n",
    "# sns.lineplot(x=\"ids_to_load_train2\", y=\"test_b_acc\", hue='run_name_tranc', data=df, errorbar=\"se\") #, None), orient='y')\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "ax = plt.gca() # Get the current axes object\n",
    "ax.set_xscale('log') # Set the y axis scale to log\n",
    "# plt.xlim([-1,100])\n",
    "plt.ylabel('Test Balanced Accuracy')\n",
    "plt.xlabel('Number of Training Samples')\n",
    "\n",
    "# save the figure as an SVG file\n",
    "plt.savefig(\"../output/pt_Won_tuh_to_nmt.svg\", format=\"svg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for TUH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import pandas as pd\n",
    "# Run wandb login on the command line and paste in your API key\n",
    "api = wandb.Api()\n",
    "# entity, project = \"mjavad\", \"tuh_sc_hps_pp3_cp_wN\"  \n",
    "entity, project = \"mjavad\", \"tuh_scaling_woN_WoAug_DefArgs\"  \n",
    "\n",
    "runs = api.runs(entity + \"/\" + project) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_runs = []\n",
    "model = []\n",
    "ids_to_load_train = []\n",
    "ids_to_load_train2 = []\n",
    "test_loss = []\n",
    "run_name = []\n",
    "pre_train = []\n",
    "test_b_acc =[]\n",
    "for run in runs:\n",
    "    if run.state == 'finished': # NMT_deep4_hps_pp3_wN_wAug_WoPt81_28jul2045_index\n",
    "        if 'ft20_deep4_NMT_scaling_wN_WAug_DefArgs_' in run.name or 'rnd20_RndNMT_scaling_wN_WAug_DefArgs_' in run.name: \n",
    "            try:\n",
    "                test_b_acc.append(run.summary['b_acc_nmt'])\n",
    "                all_runs.append(run)\n",
    "                test_loss.append(run.summary['loss_tuh'])\n",
    "                run_name.append(run.name)\n",
    "                pre_train.append(run.config[\"pre_trained\"])\n",
    "                model.append(run.config[\"model_name\"])\n",
    "                ids_to_load_train.append(run.config[\"ids_to_load_train\"])\n",
    "                ids_to_load_train2.append(run.config[\"ids_to_load_train2\"])\n",
    "            except:\n",
    "                print(run.name)\n",
    "                # run.delete()\n",
    "                \n",
    "        \n",
    "        # elif 'TUH_deep4_hps_pp3_wN_wAug_' in run.name: \n",
    "        #     all_runs.append(run)\n",
    "        #     valid_loss_w.append(run.summary['valid_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'run_name': run_name, 'Model':model, 'pre_train': pre_train,'ids_to_load_train': ids_to_load_train,'ids_to_load_train2': ids_to_load_train2, 'test_loss': test_loss, 'test_b_acc': test_b_acc})\n",
    "# df.head()\n",
    "df = df.assign(run_name_tranc = lambda x: x.run_name.str.split('_').str[:-4].str.join('_'))\n",
    "# df[\"ids_to_load_train\"] = df[\"ids_to_load_train\"].replace(0, 20)\n",
    "df.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# sns.lineplot(x=\"ids_to_load_train\", y=\"test_loss\", hue='Model', data=df, errorbar=\"se\", err_style=\"bars\")\n",
    "sns.lineplot(x=\"ids_to_load_train2\", y=\"test_b_acc\", hue='pre_train', data=df, errorbar=\"se\", err_style=\"bars\") #, None), orient='y')\n",
    "# sns.lineplot(x=\"ids_to_load_train2\", y=\"test_b_acc\", hue='run_name_tranc', data=df, errorbar=\"se\") #, None), orient='y')\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "ax = plt.gca() # Get the current axes object\n",
    "ax.set_xscale('log') # Set the y axis scale to log\n",
    "# ax.set_yscale('log') # Set the y axis scale to log\n",
    "# plt.xlim([-1,100])\n",
    "plt.ylabel('Test Balanced Accuracy')\n",
    "plt.xlabel('Number of Training Samples')\n",
    "\n",
    "# plt.savefig(\"../output/TCN_scaling_wN_WoAug_DefArgs_final_nmt.svg\", format=\"svg\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Appendix\n",
    ":P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['Model', 'ids_to_load_train2']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['Model']=='Deep4Net'].groupby(['ids_to_load_train']).std().sort_values(by='test_b_acc', ascending=False).head(20)\n",
    "# df[df['Model']=='TCN'].sort_values(by='test_b_acc', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['Model']=='TCN'].sort_values(by='test_b_acc', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run = runs[-2]\n",
    "df[df[\"ids_to_load_train2\"]==0]\n",
    "df.plot(x=\"ids_to_load_train2\", y=\"test_b_acc\", kind=\"scatter\")\n",
    "plt.xlim(0, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[df[\"ids_to_load_train2\"]][\"ids_to_load_train2\"]=1\n",
    "df[\"ids_to_load_train2\"] = df[\"ids_to_load_train2\"].replace(0, 1)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.summary.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_to_load_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
