{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "import wandb\n",
    "import pandas as pd\n",
    "from torch import seed\n",
    "from networkx import selfloop_edges\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyze wandb logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run wandb login on the command line and paste in your API key\n",
    "api = wandb.Api()\n",
    "# entity, project = \"mjavad\", \"tuh_sc_hps_pp3_cp\"  \n",
    "entity, project = \"mjavad\", \"APD_revised\"  \n",
    "\n",
    "runs = api.runs(entity + \"/\" + project) \n",
    "\n",
    "summary_list, config_list, name_list = [], [], []\n",
    "for run in runs: \n",
    "    # .summary contains output keys/values for \n",
    "    # metrics such as accuracy.\n",
    "    #  We call ._json_dict to omit large files \n",
    "    summary_list.append(run.summary._json_dict)\n",
    "\n",
    "    # .config contains the hyperparameters.\n",
    "    #  We remove special values that start with _.\n",
    "    config_list.append(\n",
    "        {k: v for k,v in run.config.items()\n",
    "         if not k.startswith('_')})\n",
    "\n",
    "    # .name is the human-readable name of the run.\n",
    "    name_list.append(run.name)\n",
    "\n",
    "runs_df = pd.DataFrame({\n",
    "    \"summary\": summary_list,\n",
    "    \"config\": config_list,\n",
    "    \"name\": name_list\n",
    "    })\n",
    "\n",
    "runs_df.to_csv(\"project.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_runs = []\n",
    "ids_to_load_train = []\n",
    "valid_loss_wo = []\n",
    "valid_loss_w = []\n",
    "for run in runs:\n",
    "    if run.state == 'finished':\n",
    "        if 'TUH_deep4_hps_pp3_wN_woAug_' in run.name: #index2_number2700\n",
    "            all_runs.append(run)\n",
    "            valid_loss_wo.append(run.summary['valid_loss'])\n",
    "        elif 'TUH_deep4_hps_pp3_wN_wAug_' in run.name: #index2_number2700\n",
    "            all_runs.append(run)\n",
    "            valid_loss_w.append(run.summary['valid_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(valid_loss_w), np.std(valid_loss_w))\n",
    "print(np.mean(valid_loss_wo),np.std(valid_loss_wo))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = zip(valid_loss_w, valid_loss_wo)#, list3, list4, list5)\n",
    "\n",
    "# Open a csv file in write mode\n",
    "with open(\"data.csv\", \"w\") as f:\n",
    "    # Create a csv writer object\n",
    "    writer = csv.writer(f, quoting=csv.QUOTE_ALL)\n",
    "    writer.writerow(['valid_loss','w=0,wo=1'])\n",
    "    for row in valid_loss_w:\n",
    "        writer.writerow([row, '0'])\n",
    "    for row in valid_loss_wo:\n",
    "        writer.writerow([row, '1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plot loss vs data size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run wandb login on the command line and paste in your API key\n",
    "api = wandb.Api()\n",
    "# entity, project = \"mjavad\", \"tuh_sc_hps_pp3_cp_wN\"  \n",
    "entity, project = \"mjavad\", \"tuh_scaling\"  \n",
    "\n",
    "runs = api.runs(entity + \"/\" + project) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_runs = []\n",
    "ids_to_load_train2 = []\n",
    "test_loss = []\n",
    "run_name = []\n",
    "pre_train = []\n",
    "test_b_acc =[]\n",
    "for run in runs:\n",
    "    if run.state == 'finished':\n",
    "        if 'NMT_deep4_hps_pp3_wN_wAug_WoPt81_index0' in run.name or 'NMT_deep4_hps_pp3_wN_wAug_WPt81_index9' in run.name: \n",
    "            try:\n",
    "                all_runs.append(run)\n",
    "                test_loss.append(run.summary['loss_nmt'])\n",
    "                test_b_acc.append(run.summary['b_acc_nmt'])\n",
    "                run_name.append(run.name)\n",
    "                pre_train.append(run.config[\"pre_trained\"])\n",
    "                ids_to_load_train2.append(run.config[\"ids_to_load_train2\"])\n",
    "            except:\n",
    "                print(run.name)\n",
    "                # run.delete()\n",
    "                \n",
    "        \n",
    "        # elif 'TUH_deep4_hps_pp3_wN_wAug_' in run.name: \n",
    "        #     all_runs.append(run)\n",
    "        #     valid_loss_w.append(run.summary['valid_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_runs = []\n",
    "ids_to_load_train2 = []\n",
    "test_loss = []\n",
    "run_name = []\n",
    "pre_train = []\n",
    "test_b_acc =[]\n",
    "for run in runs:\n",
    "    if run.state == 'finished': # NMT_deep4_hps_pp3_wN_wAug_WoPt81_28jul2045_index\n",
    "        if 'NMT_deep4_hps_pp3_woN_wAug_WoPt81_lr001_index' in run.name or 'NMT_deep4_hps_pp3_woN_wAug_WPt81_lr001_index' in run.name: \n",
    "            try:\n",
    "                all_runs.append(run)\n",
    "                test_loss.append(run.summary['loss_nmt'])\n",
    "                test_b_acc.append(run.summary['b_acc_nmt'])\n",
    "                run_name.append(run.name)\n",
    "                pre_train.append(run.config[\"pre_trained\"])\n",
    "                ids_to_load_train2.append(run.config[\"ids_to_load_train2\"])\n",
    "            except:\n",
    "                print(run.name)\n",
    "                # run.delete()\n",
    "                \n",
    "        \n",
    "        # elif 'TUH_deep4_hps_pp3_wN_wAug_' in run.name: \n",
    "        #     all_runs.append(run)\n",
    "        #     valid_loss_w.append(run.summary['valid_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame({'run_name': run_name, 'Pre-Train': pre_train,'ids_to_load_train2': ids_to_load_train2, 'test_loss': test_loss, 'test_b_acc': test_b_acc})\n",
    "# # df.head()\n",
    "# df = df.assign(run_name_tranc = lambda x: x.run_name.str.split('_').str[:-4].str.join('_'))\n",
    "# df[\"ids_to_load_train2\"] = df[\"ids_to_load_train2\"].replace(0, 20)\n",
    "# df.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# sns.lineplot(x=\"ids_to_load_train2\", y=\"test_loss\", hue='pre_train', data=df, errorbar=\"se\")\n",
    "fig = sns.lineplot(x=\"ids_to_load_train2\", y=\"test_b_acc\", hue='Pre-Train', data=df, errorbar=\"se\", err_style=\"bars\") #, None), orient='y')\n",
    "# sns.lineplot(x=\"ids_to_load_train2\", y=\"test_b_acc\", hue='run_name_tranc', data=df, errorbar=\"se\") #, None), orient='y')\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "ax = plt.gca() # Get the current axes object\n",
    "ax.set_xscale('log') # Set the y axis scale to log\n",
    "# plt.xlim([-1,100])\n",
    "plt.ylabel('Test Balanced Accuracy')\n",
    "plt.xlabel('Number of Training Samples')\n",
    "\n",
    "# save the figure as an SVG file\n",
    "# plt.savefig(\"../output/pt_Won_tuh_to_nmt.svg\", format=\"svg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for TUH/NMT random vs fine-tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run wandb login on the command line and paste in your API key\n",
    "api = wandb.Api()\n",
    "# entity, project = \"mjavad\", \"tuh_sc_hps_pp3_cp_wN\"  \n",
    "# entity, project = \"mjavad\", \"tuh_scaling_woN_WoAug_DefArgs\" # original \n",
    "entity, project = \"mjavad\", \"ft_rnd_nmt\"  # 2nd try with 20 min\n",
    "\n",
    "runs = api.runs(entity + \"/\" + project) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_runs = []\n",
    "model = []\n",
    "ids_to_load_train = []\n",
    "ids_to_load_train2 = []\n",
    "test_loss = []\n",
    "run_name = []\n",
    "pre_train = []\n",
    "test_b_acc =[]\n",
    "seeds = []\n",
    "for run in runs:\n",
    "    if run.state == 'finished': # \n",
    "        # if 'ft20_TCN_NMT_scaling_wN_WAug_DefArgs_' in run.name or 'rnd20_TCN_NMT_scaling_wN_WAug_DefArgs_' in run.name: \n",
    "        # deep4:\n",
    "        # if 'ft20_deep4_NMT_scaling_wN_WAug_DefArgs_' in run.name or 'rnd20_RndNMT_scaling_wN_WAug_DefArgs_' in run.name:# or 'ftDisLr05_rnd5_mila_Deep4Net_Merge_scaling_wN_WAug_DefArgs_': \n",
    "        if 'rnd_nmt_scaling_wN_20min_nAug_DefArgs_' in run.name or 'ft_nmt_scaling_wN_20min_nAug_DefArgs_' in run.name:# or 'ftDisLr05_rnd5_mila_Deep4Net_Merge_scaling_wN_WAug_DefArgs_':\n",
    "        # Shallow:\n",
    "        # if 'ft20_Shallow_NMT_scaling_wN_WAug_DefArgs_' in run.name or 'rnd20_Shallow_NMT_scaling_wN_WAug_DefArgs_' in run.name: \n",
    "        # if 'ft20_EEGNet_NMT_scaling_wN_WAug_DefArgs_' in run.name or 'rnd20_EEGNet_NMT_scaling_wN_WAug_DefArgs_' in run.name:\n",
    "        # EEGnet\n",
    "        # if 'ft20_mila_EEGNet_NMT_scaling_wN_WAug_DefArgs_' in run.name or 'rnd20_mila_EEGNet_NMT_scaling_wN_WAug_DefArgs_' in run.name:\n",
    "        # if 'ft20_mila_EEGNet_NMT_scaling_wN_WAug_DefArgs_revisionOct_dis09lr' in run.name or 'rnd20_mila_EEGNet_NMT_scaling_wN_WAug_DefArgs_' in run.name:\n",
    "        # TCN:\n",
    "        # if 'ft20_mila_TCN_NMT_scaling_wN_WAug_DefArgs_' in run.name or 'rnd20_mila_TCN_NMT_scaling_wN_WAug_DefArgs_index' in run.name:\n",
    "        # if 'ft20_mila_TCN_NMT_scaling_wN_WAug_DefArgs_' in run.name or 'rnd20_mila_TCN_NMT_scaling_wN_WAug_DefArgs_index' in run.name:\n",
    "            try:\n",
    "                test_b_acc.append(run.summary['b_acc_nmt']) #b_acc_nmt  loss_nmt\n",
    "                all_runs.append(run)\n",
    "                test_loss.append(run.summary['loss_tuh'])\n",
    "                run_name.append(run.name)\n",
    "                pre_train.append(run.config[\"pre_trained\"])\n",
    "                model.append(run.config[\"model_name\"])\n",
    "                ids_to_load_train.append(run.config[\"ids_to_load_train\"])\n",
    "                ids_to_load_train2.append(run.config[\"ids_to_load_train2\"])\n",
    "                seeds.append(run.config[\"seed\"])\n",
    "            except:\n",
    "                print(run.name)\n",
    "                # run.delete()\n",
    "                \n",
    "        \n",
    "        # elif 'TUH_deep4_hps_pp3_wN_wAug_' in run.name: \n",
    "        #     all_runs.append(run)\n",
    "        #     valid_loss_w.append(run.summary['valid_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'run_name': run_name, 'Model':model, 'pre_train': pre_train,'ids_to_load_train': ids_to_load_train,'ids_to_load_train2': ids_to_load_train2, 'test_loss': test_loss, 'test_b_acc': test_b_acc,\n",
    "                   'seed': seeds})\n",
    "# df.head()\n",
    "df = df.assign(run_name_tranc = lambda x: x.run_name.str.split('_').str[:-4].str.join('_')) #+ '_' + str(x.pre_train))\n",
    "\n",
    "# import numpy as np\n",
    "# df[\"run_name_tranc_pretrain\"] = df[\"run_name_tranc\"] + \"_\" + np.where(df[\"pre_train\"], \"true\", \"false\")\n",
    "\n",
    "# df = df.assign(run_name_tranc = lambda x: str(x.pre_train))\n",
    "# df[\"ids_to_load_train\"] = df[\"ids_to_load_train\"].replace(0, 20)\n",
    "df.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df[df['Model'] == 'Shallow']\n",
    "# df = df[df['Model'] == 'Deep4Net']\n",
    "df = df[df['Model'] == 'TCN_var']\n",
    "# fig = plt.figure(figsize=(16, 8))\n",
    "# sns.lineplot(x=\"ids_to_load_train\", y=\"test_loss\", hue='Model', data=df, errorbar=\"se\", err_style=\"bars\")\n",
    "# sns.lineplot(x=\"ids_to_load_train2\", y=\"test_b_acc\", hue='pre_train', data=df, errorbar=\"se\", err_style=\"band\") #, None), orient='y')\n",
    "fig = sns.lineplot(x=\"ids_to_load_train2\", y=\"test_b_acc\", hue='pre_train', data=df,ci=68)#, errorbar=\"se\", err_style=\"bars\") #, None), orient='y')\n",
    "# sns.lineplot(x=\"ids_to_load_train2\", y=\"test_b_acc\", hue='run_name_tranc', data=df, errorbar=\"se\") #, None), orient='y')\n",
    "\n",
    "fig.axes.set_yticklabels(fig.axes.get_yticks(), fontsize=24)\n",
    "fig.axes.set_xticklabels(fig.axes.get_xticks(), fontsize=24)\n",
    "\n",
    "# define a custom function to format the labels\n",
    "def format_label(x, pos):\n",
    "    return f\"{x:.2f}\"\n",
    "\n",
    "\n",
    "# create a formatter object using the custom function\n",
    "formatter = FuncFormatter(format_label)\n",
    "\n",
    "# set the formatter for the y-axis\n",
    "fig.axes.yaxis.set_major_formatter(formatter)\n",
    "\n",
    "ax = plt.gca() # Get the current axes object\n",
    "ax.set_xscale('log') # Set the y axis scale to log\n",
    "# ax.set_yscale('log') # Set the y axis scale to log\n",
    "# plt.ylim([.48,.84])\n",
    "# plt.ylim([.60,.80])\n",
    "\n",
    "# plt.xlim([30,2800])\n",
    "\n",
    "# plt.ylabel('Test Balanced Accuracy')\n",
    "# plt.xlabel('Number of Training Samples')\n",
    "\n",
    "# plt.ylabel(None)\n",
    "# plt.xlabel(None)\n",
    "\n",
    "# plt.gca().legend().remove()\n",
    "\n",
    "# plt.savefig(\"../output/eegnet_pos_trans_oct2023.svg\", format=\"svg\")\n",
    "# plt.savefig(\"../output/deep4_forget_oct2023.svg\", format=\"svg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[df[\"ids_to_load_train2\"] >1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.bo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.groupby(['Model', 'ids_to_load_train2']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[(df['ids_to_load_train2']>2000) & (df['pre_train']==False) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop  # #########################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For single vs concatinated training set (table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Run wandb login on the command line and paste in your API key\n",
    "api = wandb.Api()\n",
    "# entity, project = \"mjavad\", \"tuh_sc_hps_pp3_cp_wN\"  \n",
    "entity, project = \"mjavad\", \"tuh_scaling_woN_WoAug_DefArgs\"  \n",
    "\n",
    "runs = api.runs(entity + \"/\" + project) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_runs = []\n",
    "model = []\n",
    "ids_to_load_train = []\n",
    "ids_to_load_train2 = []\n",
    "test_loss = []\n",
    "run_name = []\n",
    "pre_train = []\n",
    "test_b_acc =[]\n",
    "for run in runs:\n",
    "    if run.state == 'finished': # NMT_deep4_hps_pp3_wN_wAug_WoPt81_28jul2045_index\n",
    "        # if 'ft20_mila_TCN_NMT_scaling_woN_WAug_DefArgs_'  in run.name : \n",
    "        # if 'ft20_mila_Deep4Net_NMT_scaling_woN_WAug_DefArgs_'  in run.name : \n",
    "        # if 'ft20_Shallow_NMT_scaling_wN_WAug_DefArgs_'  in run.name : \n",
    "        if 'ft20_EEGNet_NMT_scaling_wN_WAug_DefArgs_'  in run.name : \n",
    "        # if 'tuh_scaling_wN_WAug_DefArgs' in run.name :\n",
    "        # if 'rnd20_TCN_NMT_scaling_wN_WAug_DefArgs_' in run.name :\n",
    "        # if  'rnd20_RndNMT_scaling_wN_WAug_DefArgs_' in run.name :\n",
    "        # if  'rnd20_mila_EEGNet_NMT_scaling_wN_WAug_DefArgs_' in run.name :\n",
    "        # if 'rnd5_mila_Allmodels_merge_full_wN_WAug_DefArgs_' in run.name:\n",
    "        # if 'ft20_deep4_NMT_scaling_wN_WAug_DefArgs_' in run.name or 'rnd20_RndNMT_scaling_wN_WAug_DefArgs_' in run.name: \n",
    "        # if 'ft20_TCN_NMT_scaling_wN_WAug_DefArgs_' in run.name or 'rnd20_TCN_NMT_scaling_wN_WAug_DefArgs_' in run.name or 'ft20_mila_TCN_NMT_scaling_woN_WAug_DefArgs_' in run.name or 'rnd20_mila_TCN_NMT_scaling_woN_WAug_DefArgs_index' in run.name: \n",
    "        # if 'ft20_deep4_NMT_scaling_wN_WAug_DefArgs_' in run.name or 'rnd20_RndNMT_scaling_wN_WAug_DefArgs_' in run.name or 'ft20_mila_Deep4Net_NMT_scaling_woN_WAug_DefArgs_' in run.name or 'rnd20_mila_Deep4Net_NMT_scaling_woN_WAug_DefArgs_index' in run.name: \n",
    "        # if 'ft20_mila_TCN_NMT_scaling_woN_WAug_DefArgs_' in run.name or 'rnd20_mila_TCN_NMT_scaling_woN_WAug_DefArgs_index' in run.name:\n",
    "            try:\n",
    "                test_b_acc.append(run.summary['b_acc_merge'])\n",
    "                all_runs.append(run)\n",
    "                test_loss.append(run.summary['loss_tuh'])\n",
    "                run_name.append(run.name)\n",
    "                pre_train.append(run.config[\"pre_trained\"])\n",
    "                model.append(run.config[\"model_name\"])\n",
    "                ids_to_load_train.append(run.config[\"ids_to_load_train\"])\n",
    "                ids_to_load_train2.append(run.config[\"ids_to_load_train2\"])\n",
    "            except:\n",
    "                print(run.name)\n",
    "                # run.delete()\n",
    "                \n",
    "df = pd.DataFrame({'run_name': run_name, 'Model':model, 'pre_train': pre_train,'ids_to_load_train': ids_to_load_train,'ids_to_load_train2': ids_to_load_train2, 'test_loss': test_loss, 'test_b_acc': test_b_acc})\n",
    "# df.head()\n",
    "# df = df.assign(run_name_tranc = lambda x: x.run_name.str.split('_').str[:-4].str.join('_')) #+ '_' + str(x.pre_train))\n",
    "\n",
    "# import numpy as np\n",
    "# df[\"run_name_tranc_pretrain\"] = df[\"run_name_tranc\"] + \"_\" + np.where(df[\"pre_train\"], \"true\", \"false\")\n",
    "\n",
    "# df = df.assign(run_name_tranc = lambda x: str(x.pre_train))\n",
    "# df[\"ids_to_load_train\"] = df[\"ids_to_load_train\"].replace(0, 20)\n",
    "df.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['ids_to_load_train2'] == 2110]\n",
    "df.groupby(['Model']).std()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discriminative learning rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Run wandb login on the command line and paste in your API key\n",
    "api = wandb.Api()\n",
    "# entity, project = \"mjavad\", \"tuh_sc_hps_pp3_cp_wN\"  \n",
    "entity, project = \"mjavad\", \"tuh_scaling_woN_WoAug_DefArgs\" \n",
    "# entity, project = \"mjavad\", \"APD_revised\"  \n",
    "\n",
    "\n",
    "runs = api.runs(entity + \"/\" + project) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_runs = []\n",
    "model = []\n",
    "ids_to_load_train = []\n",
    "ids_to_load_train2 = []\n",
    "test_loss = []\n",
    "run_name = []\n",
    "pre_train = []\n",
    "test_b_acc =[]\n",
    "for run in runs:\n",
    "    if run.state == 'finished': # NMT_deep4_hps_pp3_wN_wAug_WoPt81_28jul2045_index\n",
    "        # if 'tuh_scaling_wN_WAug_DefArgs' in run.name :\n",
    "        # if 'rnd20_TCN_NMT_scaling_wN_WAug_DefArgs_' in run.name :\n",
    "        # if  'rnd20_RndNMT_scaling_wN_WAug_DefArgs_' in run.name :\n",
    "        # if  'rnd20_mila_EEGNet_NMT_scaling_wN_WAug_DefArgs_' in run.name :\n",
    "        if 'ftNormLr_rnd5_mila_Deep4Net_Merge_scaling_wN_WAug_DefArgs_' in run.name or 'ftDisLr_rnd5_mila_Deep4Net_Merge_scaling_wN_WAug_DefArgs_' in run.name or 'ftDisLr05_rnd5_mila_Deep4Net_Merge_scaling_wN_WAug_DefArgs_' in run.name:\n",
    "        # if 'ft20_deep4_NMT_scaling_wN_WAug_DefArgs_' in run.name or 'rnd20_RndNMT_scaling_wN_WAug_DefArgs_' in run.name: \n",
    "        # if 'ft20_TCN_NMT_scaling_wN_WAug_DefArgs_' in run.name or 'rnd20_TCN_NMT_scaling_wN_WAug_DefArgs_' in run.name or 'ft20_mila_TCN_NMT_scaling_woN_WAug_DefArgs_' in run.name or 'rnd20_mila_TCN_NMT_scaling_woN_WAug_DefArgs_index' in run.name: \n",
    "        # if 'ft20_deep4_NMT_scaling_wN_WAug_DefArgs_' in run.name or 'rnd20_RndNMT_scaling_wN_WAug_DefArgs_' in run.name or 'ft20_mila_Deep4Net_NMT_scaling_woN_WAug_DefArgs_' in run.name or 'rnd20_mila_Deep4Net_NMT_scaling_woN_WAug_DefArgs_index' in run.name: \n",
    "        # if 'ft20_mila_TCN_NMT_scaling_woN_WAug_DefArgs_' in run.name or 'rnd20_mila_TCN_NMT_scaling_woN_WAug_DefArgs_index' in run.name:\n",
    "            try:\n",
    "                test_b_acc.append(run.summary['b_acc_nmt'])\n",
    "                all_runs.append(run)\n",
    "                test_loss.append(run.summary['loss_tuh'])\n",
    "                run_name.append(run.name)\n",
    "                pre_train.append(run.config[\"pre_trained\"])\n",
    "                model.append(run.config[\"model_name\"])\n",
    "                ids_to_load_train.append(run.config[\"ids_to_load_train\"])\n",
    "                ids_to_load_train2.append(run.config[\"ids_to_load_train2\"])\n",
    "            except:\n",
    "                print(run.name)\n",
    "                # run.delete()\n",
    "                \n",
    "df = pd.DataFrame({'run_name': run_name, 'Model':model, 'pre_train': pre_train,'ids_to_load_train': ids_to_load_train,'ids_to_load_train2': ids_to_load_train2, 'test_loss': test_loss, 'test_b_acc': test_b_acc})\n",
    "# df.head()\n",
    "df = df.assign(run_name_tranc = lambda x: x.run_name.str.split('_').str[0]) #+ '_' + str(x.pre_train))\n",
    "\n",
    "# import numpy as np\n",
    "# df[\"run_name_tranc_pretrain\"] = df[\"run_name_tranc\"] + \"_\" + np.where(df[\"pre_train\"], \"true\", \"false\")\n",
    "\n",
    "# df = df.assign(run_name_tranc = lambda x: str(x.pre_train))\n",
    "# df[\"ids_to_load_train\"] = df[\"ids_to_load_train\"].replace(0, 20)\n",
    "df.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# fig = plt.figure(figsize=(16, 8))\n",
    "# sns.lineplot(x=\"ids_to_load_train\", y=\"test_loss\", hue='Model', data=df, errorbar=\"se\", err_style=\"bars\")\n",
    "# sns.lineplot(x=\"ids_to_load_train2\", y=\"test_b_acc\", hue='pre_train', data=df, errorbar=\"se\", err_style=\"band\") #, None), orient='y')\n",
    "sns.boxplot(x=\"run_name_tranc\", y=\"test_b_acc\", data=df, order=['ftNormLr','ftDisLr', 'ftDisLr05'])#, errorbar=\"se\", err_style=\"bars\") #, None), orient='y')\n",
    "# sns.lineplot(x=\"ids_to_load_train2\", y=\"test_b_acc\", hue='run_name_tranc', data=df, errorbar=\"se\") #, None), orient='y')\n",
    "\n",
    "# ax = plt.gca() # Get the current axes object\n",
    "# ax.set_xscale('log') # Set the y axis scale to log\n",
    "# # ax.set_yscale('log') # Set the y axis scale to log\n",
    "# # plt.xlim([-1,100])\n",
    "plt.ylabel('Test Balanced Accuracy')\n",
    "plt.xlabel('Discriminative Learning Rates')\n",
    "\n",
    "# plt.savefig(\"../output/Deep4_dis_LR.svg\", format=\"svg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('run_name_tranc').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaling model and data size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Run wandb login on the command line and paste in your API key\n",
    "api = wandb.Api()\n",
    "# entity, project = \"mjavad\", \"tuh_sc_hps_pp3_cp_wN\"  \n",
    "# entity, project = \"mjavad\", \"tuh_scaling_woN_WoAug_DefArgs\" \n",
    "entity, project = \"mjavad\", \"tuh_nFilters\" # #\"tcn_small15\" #APD_revised_CpLoss #tuh_nFilters\n",
    "\n",
    "\n",
    "runs = api.runs(entity + \"/\" + project) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "all_runs = []\n",
    "model = []\n",
    "ids_to_load_train = []\n",
    "n_tcn_blocks = []\n",
    "n_tcn_filters = []\n",
    "test_loss = []\n",
    "run_name = []\n",
    "pre_train = []\n",
    "test_b_acc =[]\n",
    "augment = []\n",
    "seed = []\n",
    "for run in runs:\n",
    "    if run.state == 'finished': # NMT_deep4_hps_pp3_wN_wAug_WoPt81_28jul2045_index\n",
    "        # if 'tuh_scaling_wN_WAug_DefArgs' in run.name :\n",
    "        # if 'rnd20_TCN_NMT_scaling_wN_WAug_DefArgs_' in run.name :\n",
    "        # if  'rnd20_RndNMT_scaling_wN_WAug_DefArgs_' in run.name :\n",
    "        # if  'rnd20_mila_EEGNet_NMT_scaling_wN_WAug_DefArgs_' in run.name :\n",
    "        # if 'tuh_size_scale_model_' in run.name:# or 'ftDisLr_rnd5_mila_Deep4Net_Merge_scaling_wN_WAug_DefArgs_' in run.name or 'ftDisLr05_rnd5_mila_Deep4Net_Merge_scaling_wN_WAug_DefArgs_' in run.name:\n",
    "        # if 'nmt_nAaug_size_scale_model_' in run.name or 'nmt_wAaug_size_scale_model_' in run.name:# or 'ftDisLr05_rnd5_mila_Deep4Net_Merge_scaling_wN_WAug_DefArgs_' in run.name:        \n",
    "        # if 'ft20_deep4_NMT_scaling_wN_WAug_DefArgs_' in run.name or 'rnd20_RndNMT_scaling_wN_WAug_DefArgs_' in run.name: \n",
    "        # if 'ft20_TCN_NMT_scaling_wN_WAug_DefArgs_' in run.name or 'rnd20_TCN_NMT_scaling_wN_WAug_DefArgs_' in run.name or 'ft20_mila_TCN_NMT_scaling_woN_WAug_DefArgs_' in run.name or 'rnd20_mila_TCN_NMT_scaling_woN_WAug_DefArgs_index' in run.name: \n",
    "        # if 'ft20_deep4_NMT_scaling_wN_WAug_DefArgs_' in run.name or 'rnd20_RndNMT_scaling_wN_WAug_DefArgs_' in run.name or 'ft20_mila_Deep4Net_NMT_scaling_woN_WAug_DefArgs_' in run.name or 'rnd20_mila_Deep4Net_NMT_scaling_woN_WAug_DefArgs_index' in run.name: \n",
    "        if 'tuh_wN_nAug_model_TCN_var_' in run.name: #or 'rnd20_mila_TCN_NMT_scaling_woN_WAug_DefArgs_index' in run.name:\n",
    "        # if 'ft20_mila_TCN_NMT_scaling_woN_WAug_DefArgs_' in run.name or 'rnd20_mila_TCN_NMT_scaling_woN_WAug_DefArgs_index' in run.name:\n",
    "            try:\n",
    "                test_b_acc.append(run.summary['b_acc_tuh']) #loss_nmt b_acc_nmt\n",
    "                all_runs.append(run)\n",
    "                test_loss.append(run.summary['loss_nmt'])\n",
    "                run_name.append(run.name)\n",
    "                pre_train.append(run.config[\"pre_trained\"])\n",
    "                model.append(run.config[\"model_name\"])\n",
    "                ids_to_load_train.append(run.config[\"ids_to_load_train\"])\n",
    "                n_tcn_blocks.append(run.config[\"n_tcn_blocks\"])\n",
    "                n_tcn_filters.append(run.config[\"n_tcn_filters\"])\n",
    "                seed.append(run.config[\"seed\"])\n",
    "                augment.append(run.config[\"augment\"])\n",
    "            except:\n",
    "                print(run.name)\n",
    "                # run.delete()\n",
    "                \n",
    "df = pd.DataFrame({'run_name': run_name, 'Model':model, 'pre_train': pre_train,'ids_to_load_train': ids_to_load_train,\n",
    "                   'n_tcn_blocks': n_tcn_blocks, 'n_tcn_filters': n_tcn_filters,\n",
    "                    'test_loss': test_loss, 'test_b_acc': test_b_acc,\n",
    "                   'seed': seed, 'augment': augment})\n",
    "# df.head()\n",
    "# df = df.assign(run_name_tranc = lambda x: x.run_name.str.split('_').str[2]) #+ '_' + str(x.pre_train))\n",
    "\n",
    "# import numpy as np\n",
    "# df[\"run_name_tranc_pretrain\"] = df[\"run_name_tranc\"] + \"_\" + np.where(df[\"pre_train\"], \"true\", \"false\")\n",
    "\n",
    "# df = df.assign(run_name_tranc = lambda x: str(x.pre_train))\n",
    "# df[\"ids_to_load_train\"] = df[\"ids_to_load_train\"].replace(0, 20)\n",
    "df.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# df = df[df['augment'] == True]\n",
    "# df = df[df['n_tcn_blocks'].isin([6])]\n",
    "# df = df[df['seed'].isin([2023])]\n",
    "# fig = plt.figure(figsize=(16, 8))\n",
    "# sns.lineplot(x=\"ids_to_load_train\", y=\"test_loss\", hue='Model', data=df, errorbar=\"se\", err_style=\"bars\")\n",
    "# sns.lineplot(x=\"ids_to_load_train2\", y=\"test_b_acc\", hue='pre_train', data=df, errorbar=\"se\", err_style=\"band\") #, None), orient='y')\n",
    "# sns.boxplot(x=\"run_name_tranc\", y=\"test_b_acc\", data=df, order=['ftNormLr','ftDisLr', 'ftDisLr05'])#, errorbar=\"se\", err_style=\"bars\") #, None), orient='y')\n",
    "# sns.lineplot(x=\"ids_to_load_train2\", y=\"test_b_acc\", hue='run_name_tranc', data=df, errorbar=\"se\") #, None), orient='y')\n",
    "# sns.lineplot(x=\"ids_to_load_train\", y=\"test_loss\", data=df, hue=\"n_tcn_blocks\")#, errorbar=\"se\", err_style=\"bars\") #, None), orient='y')\n",
    "sns.lineplot(x=\"ids_to_load_train\", y=\"test_b_acc\", data=df, hue=\"n_tcn_filters\")#, errorbar=\"se\", err_style=\"bars\") #, None), orient='y')\n",
    "# n_tcn_blocks\n",
    "\n",
    "ax = plt.gca() # Get the current axes object\n",
    "ax.set_xscale('log') # Set the y axis scale to log\n",
    "# ax.set_yscale('log') # Set the y axis scale to log\n",
    "# # plt.xlim([-1,100])\n",
    "plt.ylabel('Test Balanced Accuracy')\n",
    "plt.xlabel('Number of Training Samples')\n",
    "\n",
    "# plt.savefig(\"../output/Deep4_dis_LR.svg\", format=\"svg\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ablation: compare different pretraining methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Run wandb login on the command line and paste in your API key\n",
    "api = wandb.Api()\n",
    "# entity, project = \"mjavad\", \"tuh_sc_hps_pp3_cp_wN\"  \n",
    "# entity, project = \"mjavad\", \"tuh_scaling_woN_WoAug_DefArgs\" \n",
    "entity, project = \"mjavad\", \"tuh_ablation_pp\" # #\"tcn_small15\" #APD_revised_CpLoss #tuh_nFilters\n",
    "\n",
    "\n",
    "runs = api.runs(entity + \"/\" + project) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "all_runs = []\n",
    "model = []\n",
    "ids_to_load_train = []\n",
    "n_tcn_blocks = []\n",
    "n_tcn_filters = []\n",
    "test_loss = []\n",
    "run_name = []\n",
    "pre_train = []\n",
    "test_b_acc =[]\n",
    "augment = []\n",
    "seed = []\n",
    "for run in runs:\n",
    "    if run.state == 'finished': # NMT_deep4_hps_pp3_wN_wAug_WoPt81_28jul2045_index\n",
    "        # if 'tuh_scaling_wN_WAug_DefArgs' in run.name :\n",
    "        # if 'rnd20_TCN_NMT_scaling_wN_WAug_DefArgs_' in run.name :\n",
    "        # if  'rnd20_RndNMT_scaling_wN_WAug_DefArgs_' in run.name :\n",
    "        # if  'rnd20_mila_EEGNet_NMT_scaling_wN_WAug_DefArgs_' in run.name :\n",
    "        # if 'tuh_size_scale_model_' in run.name:# or 'ftDisLr_rnd5_mila_Deep4Net_Merge_scaling_wN_WAug_DefArgs_' in run.name or 'ftDisLr05_rnd5_mila_Deep4Net_Merge_scaling_wN_WAug_DefArgs_' in run.name:\n",
    "        # if 'nmt_nAaug_size_scale_model_' in run.name or 'nmt_wAaug_size_scale_model_' in run.name:# or 'ftDisLr05_rnd5_mila_Deep4Net_Merge_scaling_wN_WAug_DefArgs_' in run.name:        \n",
    "        # if 'ft20_deep4_NMT_scaling_wN_WAug_DefArgs_' in run.name or 'rnd20_RndNMT_scaling_wN_WAug_DefArgs_' in run.name: \n",
    "        # if 'ft20_TCN_NMT_scaling_wN_WAug_DefArgs_' in run.name or 'rnd20_TCN_NMT_scaling_wN_WAug_DefArgs_' in run.name or 'ft20_mila_TCN_NMT_scaling_woN_WAug_DefArgs_' in run.name or 'rnd20_mila_TCN_NMT_scaling_woN_WAug_DefArgs_index' in run.name: \n",
    "        # if 'ft20_deep4_NMT_scaling_wN_WAug_DefArgs_' in run.name or 'rnd20_RndNMT_scaling_wN_WAug_DefArgs_' in run.name or 'ft20_mila_Deep4Net_NMT_scaling_woN_WAug_DefArgs_' in run.name or 'rnd20_mila_Deep4Net_NMT_scaling_woN_WAug_DefArgs_index' in run.name: \n",
    "        if 'tuh_nzscore20min_n01_4B128_valNMT_model_' in run.name or 'tuh_nzscore5min_n01_4B128_valNMT_model_' in run.name or 'tuh_wzscore20min_n01_4B128_valNMT_model_' in run.name or 'tuh_wzscore5min_n01_4B128_valNMT_model_' in run.name:\n",
    "        # if 'ft20_mila_TCN_NMT_scaling_woN_WAug_DefArgs_' in run.name or 'rnd20_mila_TCN_NMT_scaling_woN_WAug_DefArgs_index' in run.name:\n",
    "            try:\n",
    "                test_b_acc.append(run.summary['b_acc_nmt']) #loss_nmt b_acc_nmt\n",
    "                all_runs.append(run)\n",
    "                test_loss.append(run.summary['loss_nmt'])\n",
    "                run_name.append(run.name)\n",
    "                pre_train.append(run.config[\"pre_trained\"])\n",
    "                model.append(run.config[\"model_name\"])\n",
    "                ids_to_load_train.append(run.config[\"ids_to_load_train\"])\n",
    "                n_tcn_blocks.append(run.config[\"n_tcn_blocks\"])\n",
    "                n_tcn_filters.append(run.config[\"n_tcn_filters\"])\n",
    "                seed.append(run.config[\"seed\"])\n",
    "                augment.append(run.config[\"augment\"])\n",
    "            except:\n",
    "                print(run.name)\n",
    "                # run.delete()\n",
    "                \n",
    "df = pd.DataFrame({'run_name': run_name, 'Model':model, 'pre_train': pre_train,'ids_to_load_train': ids_to_load_train,\n",
    "                   'n_tcn_blocks': n_tcn_blocks, 'n_tcn_filters': n_tcn_filters,\n",
    "                    'test_loss': test_loss, 'test_b_acc': test_b_acc,\n",
    "                   'seed': seed, 'augment': augment})\n",
    "# df.head()\n",
    "df = df.assign(run_name_tranc = lambda x: x.run_name.str.split('_').str[1]) #+ '_' + str(x.pre_train))\n",
    "\n",
    "df = df.assign(zscore_status = lambda x: x.run_name_tranc.str[0]) #+ '_' + str(x.pre_train))\n",
    "df = df.assign(min_status = lambda x: x.run_name_tranc.str[-4:-3]) #+ '_' + str(x.pre_train))\n",
    "\n",
    "# import numpy as np\n",
    "# df[\"run_name_tranc_pretrain\"] = df[\"run_name_tranc\"] + \"_\" + np.where(df[\"pre_train\"], \"true\", \"false\")\n",
    "\n",
    "# df = df.assign(run_name_tranc = lambda x: str(x.pre_train))\n",
    "# df[\"ids_to_load_train\"] = df[\"ids_to_load_train\"].replace(0, 20)\n",
    "df.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# df = df[df['augment'] == True]\n",
    "# df = df[df['n_tcn_blocks'].isin([6])]\n",
    "# df = df[df['seed'].isin([2023])]\n",
    "# fig = plt.figure(figsize=(16, 8))\n",
    "# sns.lineplot(x=\"ids_to_load_train\", y=\"test_loss\", hue='Model', data=df, errorbar=\"se\", err_style=\"bars\")\n",
    "# sns.lineplot(x=\"ids_to_load_train2\", y=\"test_b_acc\", hue='pre_train', data=df, errorbar=\"se\", err_style=\"band\") #, None), orient='y')\n",
    "fig = sns.boxplot(x=\"min_status\", y=\"test_b_acc\", hue=\"zscore_status\", data=df, order=[\"5\",\"0\"], hue_order=[\"n\",\"w\"])#, order=['nzscore5min','wzscore5min','nzscore20min', 'wzscore20min'])#, errorbar=\"se\", err_style=\"bars\") #, None), orient='y')\n",
    "# sns.lineplot(x=\"ids_to_load_train2\", y=\"test_b_acc\", hue='run_name_tranc', data=df, errorbar=\"se\") #, None), orient='y')\n",
    "# sns.lineplot(x=\"ids_to_load_train\", y=\"test_loss\", data=df, hue=\"n_tcn_blocks\")#, errorbar=\"se\", err_style=\"bars\") #, None), orient='y')\n",
    "# sns.lineplot(x=\"ids_to_load_train\", y=\"test_b_acc\", data=df, hue=\"n_tcn_filters\")#, errorbar=\"se\", err_style=\"bars\") #, None), orient='y')\n",
    "# n_tcn_blocks\n",
    "\n",
    "ax = plt.gca() # Get the current axes object\n",
    "# ax.set_xscale('log') # Set the y axis scale to log\n",
    "# ax.set_yscale('log') # Set the y axis scale to log\n",
    "# # plt.xlim([-1,100])\n",
    "# plt.ylabel('Test Balanced Accuracy')\n",
    "# plt.xlabel('Number of Training Samples')\n",
    "\n",
    "# Change the y-axis font size to 24\n",
    "# Get the 2D array of Axes objects\n",
    "# axes = \n",
    "fig.axes.set_yticklabels(ax.get_yticks(), fontsize=24)\n",
    "\n",
    "# define a custom function to format the labels\n",
    "def format_label(x, pos):\n",
    "    return f\"{x:.2f}\"\n",
    "\n",
    "\n",
    "# create a formatter object using the custom function\n",
    "formatter = FuncFormatter(format_label)\n",
    "\n",
    "# set the formatter for the y-axis\n",
    "fig.axes.yaxis.set_major_formatter(formatter)\n",
    "\n",
    "plt.savefig(\"../output/Abl_oodNMT_wnzscore_5_20min.svg\", format=\"svg\")\n",
    "# plt.savefig(\"../output/Abl_iidTUAB_wnzscore_5_20min.svg\", format=\"svg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdcfe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "well known Models scaling with data size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run wandb login on the command line and paste in your API key\n",
    "api = wandb.Api()\n",
    "# entity, project = \"mjavad\", \"tuh_sc_hps_pp3_cp_wN\"  \n",
    "entity, project = \"mjavad\", \"tuh_scaling_woN_WoAug_DefArgs\"  \n",
    "\n",
    "runs = api.runs(entity + \"/\" + project) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_runs = []\n",
    "model = []\n",
    "ids_to_load_train = []\n",
    "ids_to_load_train2 = []\n",
    "test_loss = []\n",
    "run_name = []\n",
    "pre_train = []\n",
    "test_b_acc =[]\n",
    "for run in runs:\n",
    "    if run.state == 'finished': # NMT_deep4_hps_pp3_wN_wAug_WoPt81_28jul2045_index\n",
    "        # if 'ft20_mila_TCN_NMT_scaling_woN_WAug_DefArgs_'  in run.name : \n",
    "        # if 'ft20_mila_Deep4Net_NMT_scaling_woN_WAug_DefArgs_'  in run.name : \n",
    "        # if 'ft20_Shallow_NMT_scaling_wN_WAug_DefArgs_'  in run.name : \n",
    "        # if 'ft20_EEGNet_NMT_scaling_wN_WAug_DefArgs_'  in run.name : \n",
    "        # fig_scaling onn the paper\n",
    "        # if 'tuh_scaling_wN_WAug_DefArgs' in run.name :\n",
    "        # revision scaling with 20 min data\n",
    "        if 'tuh_scaling_wN_20min_nAug_DefArgs_' in run.name :\n",
    "        # if 'rnd20_TCN_NMT_scaling_wN_WAug_DefArgs_' in run.name :\n",
    "        # if  'rnd20_RndNMT_scaling_wN_WAug_DefArgs_' in run.name :\n",
    "        # if  'rnd20_mila_EEGNet_NMT_scaling_wN_WAug_DefArgs_' in run.name :\n",
    "        # if 'rnd5_mila_Allmodels_merge_full_wN_WAug_DefArgs_' in run.name:\n",
    "        # if 'ft20_deep4_NMT_scaling_wN_WAug_DefArgs_' in run.name or 'rnd20_RndNMT_scaling_wN_WAug_DefArgs_' in run.name: \n",
    "        # if 'ft20_TCN_NMT_scaling_wN_WAug_DefArgs_' in run.name or 'rnd20_TCN_NMT_scaling_wN_WAug_DefArgs_' in run.name or 'ft20_mila_TCN_NMT_scaling_woN_WAug_DefArgs_' in run.name or 'rnd20_mila_TCN_NMT_scaling_woN_WAug_DefArgs_index' in run.name: \n",
    "        # if 'ft20_deep4_NMT_scaling_wN_WAug_DefArgs_' in run.name or 'rnd20_RndNMT_scaling_wN_WAug_DefArgs_' in run.name or 'ft20_mila_Deep4Net_NMT_scaling_woN_WAug_DefArgs_' in run.name or 'rnd20_mila_Deep4Net_NMT_scaling_woN_WAug_DefArgs_index' in run.name: \n",
    "        # if 'ft20_mila_TCN_NMT_scaling_woN_WAug_DefArgs_' in run.name or 'rnd20_mila_TCN_NMT_scaling_woN_WAug_DefArgs_index' in run.name:\n",
    "            try:\n",
    "                test_b_acc.append(run.summary['b_acc_nmt']) #b_acc_nmt\n",
    "                all_runs.append(run)\n",
    "                test_loss.append(run.summary['loss_tuh'])\n",
    "                run_name.append(run.name)\n",
    "                pre_train.append(run.config[\"pre_trained\"])\n",
    "                model.append(run.config[\"model_name\"])\n",
    "                ids_to_load_train.append(run.config[\"ids_to_load_train\"])\n",
    "                ids_to_load_train2.append(run.config[\"ids_to_load_train2\"])\n",
    "            except:\n",
    "                print(run.name)\n",
    "                # run.delete()\n",
    "                \n",
    "df = pd.DataFrame({'run_name': run_name, 'Model':model, 'pre_train': pre_train,'ids_to_load_train': ids_to_load_train,'ids_to_load_train2': ids_to_load_train2, 'test_loss': test_loss, 'test_b_acc': test_b_acc})\n",
    "# df.head()\n",
    "# df = df.assign(run_name_tranc = lambda x: x.run_name.str.split('_').str[:-4].str.join('_')) #+ '_' + str(x.pre_train))\n",
    "\n",
    "# import numpy as np\n",
    "# df[\"run_name_tranc_pretrain\"] = df[\"run_name_tranc\"] + \"_\" + np.where(df[\"pre_train\"], \"true\", \"false\")\n",
    "\n",
    "# df = df.assign(run_name_tranc = lambda x: str(x.pre_train))\n",
    "# df[\"ids_to_load_train\"] = df[\"ids_to_load_train\"].replace(0, 20)\n",
    "df.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_org = df.copy()\n",
    "# df = df[df['augment'] == True]\n",
    "# df = df[df['n_tcn_blocks'].isin([1])]\n",
    "# df = df[df['n_tcn_filters']< 128]\n",
    "# df = df[df['n_tcn_filters']==64]\n",
    "# df = df[df['n_tcn_filters'].isin([4,64])]\n",
    "\n",
    "\n",
    "# df = df[df['seed'].isin([2023])]\n",
    "# fig = plt.figure(figsize=(16, 8))\n",
    "# sns.lineplot(x=\"ids_to_load_train\", y=\"test_loss\", hue='Model', data=df, errorbar=\"se\", err_style=\"bars\")\n",
    "# sns.lineplot(x=\"ids_to_load_train2\", y=\"test_b_acc\", hue='pre_train', data=df, errorbar=\"se\", err_style=\"band\") #, None), orient='y')\n",
    "# sns.boxplot(x=\"run_name_tranc\", y=\"test_b_acc\", data=df, order=['nzscore5min','wzscore5min','nzscore20min', 'wzscore20min'])#, errorbar=\"se\", err_style=\"bars\") #, None), orient='y')\n",
    "# sns.lineplot(x=\"ids_to_load_train2\", y=\"test_b_acc\", hue='run_name_tranc', data=df, errorbar=\"se\") #, None), orient='y')\n",
    "# sns.lineplot(x=\"ids_to_load_train\", y=\"test_loss\", data=df, hue=\"n_tcn_blocks\")#, errorbar=\"se\", err_style=\"bars\") #, None), orient='y')\n",
    "fig = sns.lineplot(x=\"ids_to_load_train\", y=\"test_b_acc\", data=df, hue=\"Model\", ci=68, hue_order=[\"EEGNet\", \"Shallow\", \"Deep4Net\", \"TCN\"])#, err_style=\"bars\") #, None), orient='y') , err_style=\"bars\"\n",
    "# n_tcn_blocks\n",
    "\n",
    "# Plot the original data\n",
    "# sns.lineplot(x=\"ids_to_load_train\", y=\"test_b_acc\", data=df, hue=\"n_tcn_filters\", ci=68)\n",
    "\n",
    "# Apply a 10 percent smoothing using gaussian_filter1d\n",
    "# from scipy.ndimage import gaussian_filter1d\n",
    "# y_smooth = gaussian_filter1d(df[\"test_b_acc\"], sigma=0.01 * df.shape[0])\n",
    "# sns.lineplot(x=\"ids_to_load_train\", y=y_smooth, data=df, hue=\"n_tcn_filters\")\n",
    "\n",
    "\n",
    "\n",
    "fig.axes.set_yticklabels(fig.axes.get_yticks(), fontsize=24)\n",
    "fig.axes.set_xticklabels(fig.axes.get_xticks(), fontsize=24)\n",
    "\n",
    "# define a custom function to format the labels\n",
    "def format_label(x, pos):\n",
    "    return f\"{x:.2f}\"\n",
    "\n",
    "\n",
    "# create a formatter object using the custom function\n",
    "formatter = FuncFormatter(format_label)\n",
    "\n",
    "# set the formatter for the y-axis\n",
    "fig.axes.yaxis.set_major_formatter(formatter)\n",
    "\n",
    "ax = plt.gca() # Get the current axes object\n",
    "ax.set_xscale('log') # Set the y axis scale to log\n",
    "# ax.set_yscale('log') # Set the y axis scale to log\n",
    "# plt.ylim([.48,.83])\n",
    "plt.ylim([.48,.713])\n",
    "# plt.xlim([200, 600])\n",
    "\n",
    "# plt.ylabel('Test Balanced Accuracy')\n",
    "# plt.xlabel('Number of Training Samples')\n",
    "\n",
    "plt.ylabel(None)\n",
    "plt.xlabel(None)\n",
    "\n",
    "# plt.gca().legend().remove()\n",
    "\n",
    "# plt.savefig(\"../output/all_wellKnown_oodNMT.svg\", format=\"svg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)\n",
    "df2 = df[df['ids_to_load_train'] == 31]\n",
    "df3 = df2[df2['Model'] == 'Deep4Net']\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of TNC filters effect "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Run wandb login on the command line and paste in your API key\n",
    "api = wandb.Api()\n",
    "# entity, project = \"mjavad\", \"tuh_sc_hps_pp3_cp_wN\"  \n",
    "# entity, project = \"mjavad\", \"tuh_scaling_woN_WoAug_DefArgs\" \n",
    "entity, project = \"mjavad\", \"tuh_ablation_nf_clean\" # #\"tcn_small15\" #APD_revised_CpLoss #tuh_nFilters\n",
    "\n",
    "\n",
    "runs = api.runs(entity + \"/\" + project) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "all_runs = []\n",
    "model = []\n",
    "ids_to_load_train = []\n",
    "n_tcn_blocks = []\n",
    "n_tcn_filters = []\n",
    "test_loss = []\n",
    "run_name = []\n",
    "pre_train = []\n",
    "test_b_acc =[]\n",
    "augment = []\n",
    "seed = []\n",
    "for run in runs:\n",
    "    if run.state == 'finished': # NMT_deep4_hps_pp3_wN_wAug_WoPt81_28jul2045_index\n",
    "        # if 'tuh_scaling_wN_WAug_DefArgs' in run.name :\n",
    "        # if 'rnd20_TCN_NMT_scaling_wN_WAug_DefArgs_' in run.name :\n",
    "        # if  'rnd20_RndNMT_scaling_wN_WAug_DefArgs_' in run.name :\n",
    "        # if  'rnd20_mila_EEGNet_NMT_scaling_wN_WAug_DefArgs_' in run.name :\n",
    "        # if 'tuh_size_scale_model_' in run.name:# or 'ftDisLr_rnd5_mila_Deep4Net_Merge_scaling_wN_WAug_DefArgs_' in run.name or 'ftDisLr05_rnd5_mila_Deep4Net_Merge_scaling_wN_WAug_DefArgs_' in run.name:\n",
    "        # if 'nmt_nAaug_size_scale_model_' in run.name or 'nmt_wAaug_size_scale_model_' in run.name:# or 'ftDisLr05_rnd5_mila_Deep4Net_Merge_scaling_wN_WAug_DefArgs_' in run.name:        \n",
    "        # if 'ft20_deep4_NMT_scaling_wN_WAug_DefArgs_' in run.name or 'rnd20_RndNMT_scaling_wN_WAug_DefArgs_' in run.name: \n",
    "        # if 'ft20_TCN_NMT_scaling_wN_WAug_DefArgs_' in run.name or 'rnd20_TCN_NMT_scaling_wN_WAug_DefArgs_' in run.name or 'ft20_mila_TCN_NMT_scaling_woN_WAug_DefArgs_' in run.name or 'rnd20_mila_TCN_NMT_scaling_woN_WAug_DefArgs_index' in run.name: \n",
    "        # if 'ft20_deep4_NMT_scaling_wN_WAug_DefArgs_' in run.name or 'rnd20_RndNMT_scaling_wN_WAug_DefArgs_' in run.name or 'ft20_mila_Deep4Net_NMT_scaling_woN_WAug_DefArgs_' in run.name or 'rnd20_mila_Deep4Net_NMT_scaling_woN_WAug_DefArgs_index' in run.name: \n",
    "        # if 'tuh_wzscore20min_n01_nBn_model_' in run.name:# or 'tuh_nzscore5min_n01_4B128_valNMT_model_' in run.name or 'tuh_wzscore20min_n01_4B128_valNMT_model_' in run.name or 'tuh_wzscore5min_n01_4B128_valNMT_model_' in run.name:\n",
    "        if 'tuh_wzscore20min_n01_nBlocks_nBn_model_' in run.name or 'tuh_wzscore20min_n01_nBn_model_' in run.name:# or 'tuh_wzscore20min_n01_4B128_valNMT_model_' in run.name or 'tuh_wzscore5min_n01_4B128_valNMT_model_' in run.name:\n",
    "        # if 'ft20_mila_TCN_NMT_scaling_woN_WAug_DefArgs_' in run.name or 'rnd20_mila_TCN_NMT_scaling_woN_WAug_DefArgs_index' in run.name:\n",
    "            try:\n",
    "                test_b_acc.append(run.summary['loss_nmt']) #loss_nmt b_acc_nmt\n",
    "                all_runs.append(run)\n",
    "                test_loss.append(run.summary['loss_nmt'])\n",
    "                run_name.append(run.name)\n",
    "                pre_train.append(run.config[\"pre_trained\"])\n",
    "                model.append(run.config[\"model_name\"])\n",
    "                ids_to_load_train.append(run.config[\"ids_to_load_train\"])\n",
    "                n_tcn_blocks.append(run.config[\"n_tcn_blocks\"])\n",
    "                n_tcn_filters.append(run.config[\"n_tcn_filters\"])\n",
    "                seed.append(run.config[\"seed\"])\n",
    "                augment.append(run.config[\"augment\"])\n",
    "            except:\n",
    "                print(run.name)\n",
    "                # run.delete()\n",
    "                \n",
    "df = pd.DataFrame({'run_name': run_name, 'Model':model, 'pre_train': pre_train,'ids_to_load_train': ids_to_load_train,\n",
    "                   'n_tcn_blocks': n_tcn_blocks, 'n_tcn_filters': n_tcn_filters,\n",
    "                    'test_loss': test_loss, 'test_b_acc': test_b_acc,\n",
    "                   'seed': seed, 'augment': augment})\n",
    "# df.head()\n",
    "df = df.assign(run_name_tranc = lambda x: x.run_name.str.split('_').str[1]) #+ '_' + str(x.pre_train))\n",
    "\n",
    "# import numpy as np\n",
    "# df[\"run_name_tranc_pretrain\"] = df[\"run_name_tranc\"] + \"_\" + np.where(df[\"pre_train\"], \"true\", \"false\")\n",
    "\n",
    "# df = df.assign(run_name_tranc = lambda x: str(x.pre_train))\n",
    "# df[\"ids_to_load_train\"] = df[\"ids_to_load_train\"].replace(0, 20)\n",
    "df.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df_org = df.copy()\n",
    "# df = df[df['augment'] == True]\n",
    "df = df[df['n_tcn_blocks'].isin([1])]\n",
    "df = df[df['n_tcn_filters']< 128]\n",
    "# df = df[df['n_tcn_filters']==64]\n",
    "# df = df[df['n_tcn_filters'].isin([4,64])]\n",
    "\n",
    "\n",
    "# df = df[df['seed'].isin([2023])]\n",
    "# fig = plt.figure(figsize=(16, 8))\n",
    "# sns.lineplot(x=\"ids_to_load_train\", y=\"test_loss\", hue='Model', data=df, errorbar=\"se\", err_style=\"bars\")\n",
    "# sns.lineplot(x=\"ids_to_load_train2\", y=\"test_b_acc\", hue='pre_train', data=df, errorbar=\"se\", err_style=\"band\") #, None), orient='y')\n",
    "# sns.boxplot(x=\"run_name_tranc\", y=\"test_b_acc\", data=df, order=['nzscore5min','wzscore5min','nzscore20min', 'wzscore20min'])#, errorbar=\"se\", err_style=\"bars\") #, None), orient='y')\n",
    "# sns.lineplot(x=\"ids_to_load_train2\", y=\"test_b_acc\", hue='run_name_tranc', data=df, errorbar=\"se\") #, None), orient='y')\n",
    "# sns.lineplot(x=\"ids_to_load_train\", y=\"test_loss\", data=df, hue=\"n_tcn_blocks\")#, errorbar=\"se\", err_style=\"bars\") #, None), orient='y')\n",
    "fig = sns.lineplot(x=\"ids_to_load_train\", y=\"test_b_acc\", data=df, hue=\"n_tcn_filters\", ci=68)#, err_style=\"bars\") #, None), orient='y')\n",
    "# n_tcn_blocks\n",
    "\n",
    "# Plot the original data\n",
    "# sns.lineplot(x=\"ids_to_load_train\", y=\"test_b_acc\", data=df, hue=\"n_tcn_filters\", ci=68)\n",
    "\n",
    "# Apply a 10 percent smoothing using gaussian_filter1d\n",
    "# from scipy.ndimage import gaussian_filter1d\n",
    "# y_smooth = gaussian_filter1d(df[\"test_b_acc\"], sigma=0.01 * df.shape[0])\n",
    "# sns.lineplot(x=\"ids_to_load_train\", y=y_smooth, data=df, hue=\"n_tcn_filters\")\n",
    "\n",
    "\n",
    "\n",
    "fig.axes.set_yticklabels(fig.axes.get_yticks(), fontsize=24)\n",
    "fig.axes.set_xticklabels(fig.axes.get_xticks(), fontsize=24)\n",
    "\n",
    "# define a custom function to format the labels\n",
    "def format_label(x, pos):\n",
    "    return f\"{x:.2f}\"\n",
    "\n",
    "\n",
    "# create a formatter object using the custom function\n",
    "formatter = FuncFormatter(format_label)\n",
    "\n",
    "# set the formatter for the y-axis\n",
    "fig.axes.yaxis.set_major_formatter(formatter)\n",
    "\n",
    "ax = plt.gca() # Get the current axes object\n",
    "ax.set_xscale('log') # Set the y axis scale to log\n",
    "# ax.set_yscale('log') # Set the y axis scale to log\n",
    "# plt.ylim([.48,.71])\n",
    "# plt.ylabel('Test Balanced Accuracy')\n",
    "# plt.xlabel('Number of Training Samples')\n",
    "\n",
    "plt.ylabel(None)\n",
    "plt.xlabel(None)\n",
    "\n",
    "# plt.gca().legend().remove()\n",
    "\n",
    "# plt.savefig(\"../output/tcn_nf_oodNMT.svg\", format=\"svg\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plot number of TNC blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_org.copy()\n",
    "\n",
    "\n",
    "\n",
    "# df_org = df.copy()\n",
    "# df = df[df['augment'] == True]\n",
    "# df = df[df['n_tcn_blocks'].isin([1,4])]\n",
    "# df = df[df['n_tcn_filters']< 128]\n",
    "df = df[df['n_tcn_filters']==8]\n",
    "\n",
    "# df = df[df['seed'].isin([2023])]\n",
    "# fig = plt.figure(figsize=(16, 8))\n",
    "# sns.lineplot(x=\"ids_to_load_train\", y=\"test_loss\", hue='Model', data=df, errorbar=\"se\", err_style=\"bars\")\n",
    "# sns.lineplot(x=\"ids_to_load_train2\", y=\"test_b_acc\", hue='pre_train', data=df, errorbar=\"se\", err_style=\"band\") #, None), orient='y')\n",
    "# sns.boxplot(x=\"run_name_tranc\", y=\"test_b_acc\", data=df, order=['nzscore5min','wzscore5min','nzscore20min', 'wzscore20min'])#, errorbar=\"se\", err_style=\"bars\") #, None), orient='y')\n",
    "# sns.lineplot(x=\"ids_to_load_train2\", y=\"test_b_acc\", hue='run_name_tranc', data=df, errorbar=\"se\") #, None), orient='y')\n",
    "# sns.lineplot(x=\"ids_to_load_train\", y=\"test_loss\", data=df, hue=\"n_tcn_blocks\")#, errorbar=\"se\", err_style=\"bars\") #, None), orient='y')\n",
    "fig=sns.lineplot(x=\"ids_to_load_train\", y=\"test_b_acc\", data=df, hue=\"n_tcn_blocks\", ci=68)#, errorbar=\"se\", err_style=\"bars\") #, None), orient='y')\n",
    "# n_tcn_blocks\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fig.axes.set_yticklabels(fig.axes.get_yticks(), fontsize=24)\n",
    "fig.axes.set_xticklabels(fig.axes.get_xticks(), fontsize=24)\n",
    "\n",
    "# define a custom function to format the labels\n",
    "def format_label(x, pos):\n",
    "    return f\"{x:.2f}\"\n",
    "\n",
    "\n",
    "# create a formatter object using the custom function\n",
    "formatter = FuncFormatter(format_label)\n",
    "\n",
    "# set the formatter for the y-axis\n",
    "fig.axes.yaxis.set_major_formatter(formatter)\n",
    "\n",
    "ax = plt.gca() # Get the current axes object\n",
    "ax.set_xscale('log') # Set the y axis scale to log\n",
    "# ax.set_yscale('log') # Set the y axis scale to log\n",
    "# plt.ylim([.48,.83])\n",
    "# plt.ylabel('Test Balanced Accuracy')\n",
    "# plt.xlabel('Number of Training Samples')\n",
    "\n",
    "plt.ylabel(None)\n",
    "plt.xlabel(None)\n",
    "\n",
    "plt.gca().legend().remove()\n",
    "\n",
    "# plt.savefig(\"../output/tcn_nb_iidtuh.svg\", format=\"svg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[df[\"n_tcn_blocks\"]==6]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sex clf results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run wandb login on the command line and paste in your API key\n",
    "api = wandb.Api()\n",
    "# entity, project = \"mjavad\", \"tuh_sc_hps_pp3_cp_wN\"  \n",
    "entity, project = \"mjavad\", \"EEG_sex_narval\"  \n",
    "\n",
    "runs = api.runs(entity + \"/\" + project) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_runs = []\n",
    "model = []\n",
    "test_set_nmt_normal_male = []\n",
    "test_set_nmt_abnormal_male = []\n",
    "test_set_nmt_normal_female = []\n",
    "test_set_nmt_abnormal_female = []\n",
    "\n",
    "for run in runs:\n",
    "    if run.state == 'finished': # NMT_deep4_hps_pp3_wN_wAug_WoPt81_28jul2045_index\n",
    "        if 'NMT_test_subgroups_wZscore5min_w11_wAug_model_' in run.name: # or 'TUH_wZscore5min_w11_wAug_model_' in run.name:# or 'tuh_wzscore20min_n01_4B128_valNMT_model_' in run.name or 'tuh_wzscore5min_n01_4B128_valNMT_model_' in run.name:\n",
    "\n",
    "            try:\n",
    "                test_set_nmt_normal_male.append(run.summary['test_set_nmt_normal_male']) \n",
    "                test_set_nmt_abnormal_male.append(run.summary['test_set_nmt_abnormal_male']) \n",
    "                test_set_nmt_normal_female.append(run.summary['test_set_nmt_normal_female']) \n",
    "                test_set_nmt_abnormal_female.append(run.summary['test_set_nmt_abnormal_female']) \n",
    "                \n",
    "            except:\n",
    "                print(run.name)\n",
    "                # run.delete()\n",
    "                \n",
    "df = pd.DataFrame({'test_set_nmt_normal_male':test_set_nmt_normal_male,\n",
    "                   'test_set_nmt_abnormal_male':test_set_nmt_abnormal_male,\n",
    "                   'test_set_nmt_normal_female':test_set_nmt_normal_female,\n",
    "                   'test_set_nmt_abnormal_female':test_set_nmt_abnormal_female\n",
    "                   })\n",
    "# df.head()\n",
    "# df = df.assign(run_name_tranc = lambda x: x.run_name.str.split('_').str[1]) #+ '_' + str(x.pre_train))\n",
    "\n",
    "# import numpy as np\n",
    "# df[\"run_name_tranc_pretrain\"] = df[\"run_name_tranc\"] + \"_\" + np.where(df[\"pre_train\"], \"true\", \"false\")\n",
    "\n",
    "# df = df.assign(run_name_tranc = lambda x: str(x.pre_train))\n",
    "# df[\"ids_to_load_train\"] = df[\"ids_to_load_train\"].replace(0, 20)\n",
    "df.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# Assuming df is your DataFrame and the columns are as you mentioned\n",
    "df_melted = df.melt( value_vars=['test_set_nmt_normal_male', 'test_set_nmt_abnormal_male', 'test_set_nmt_normal_female', 'test_set_nmt_abnormal_female'], var_name='Category', value_name='test_acc')\n",
    "\n",
    "# # Extract gender and condition from the Category\n",
    "df_melted['Gender'] = df_melted['Category'].apply(lambda x: 'Female' if 'female' in x else 'Male')\n",
    "df_melted['Condition'] = df_melted['Category'].apply(lambda x: 'Abnormal' if 'abnormal' in x else 'Normal')\n",
    "\n",
    "# # Now plot\n",
    "fig = sns.boxplot(x='Gender', y='test_acc', data=df_melted, hue='Condition', order=['Female', 'Male'], hue_order=['Abnormal', 'Normal'])\n",
    "\n",
    "\n",
    "\n",
    "fig.axes.set_yticklabels(fig.axes.get_yticks(), fontsize=24)\n",
    "# fig.axes.set_xticklabels(fig.axes.get_xticks(), fontsize=24)\n",
    "\n",
    "# define a custom function to format the labels\n",
    "def format_label(x, pos):\n",
    "    return f\"{x:.2f}\"\n",
    "\n",
    "\n",
    "# create a formatter object using the custom function\n",
    "formatter = FuncFormatter(format_label)\n",
    "\n",
    "# set the formatter for the y-axis\n",
    "fig.axes.yaxis.set_major_formatter(formatter)\n",
    "\n",
    "ax = plt.gca() # Get the current axes object\n",
    "# ax.set_xscale('log') # Set the y axis scale to log\n",
    "# ax.set_yscale('log') # Set the y axis scale to log\n",
    "plt.ylim([.48,.93])\n",
    "# plt.ylabel('Test Balanced Accuracy')\n",
    "# plt.xlabel('Number of Training Samples')\n",
    "\n",
    "plt.ylabel(None)\n",
    "plt.xlabel(None)\n",
    "\n",
    "plt.gca().legend().remove()\n",
    "\n",
    "# plt.savefig(\"../output/sex_imbalance_MF_NA_shallow_iidnmt.svg\", format=\"svg\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sex detection results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run wandb login on the command line and paste in your API key\n",
    "api = wandb.Api()\n",
    "# entity, project = \"mjavad\", \"tuh_sc_hps_pp3_cp_wN\"  \n",
    "entity, project = \"mjavad\", \"EEG_sex_report_final\"  \n",
    "\n",
    "runs = api.runs(entity + \"/\" + project) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import NaN\n",
    "\n",
    "\n",
    "all_runs = []\n",
    "model = []\n",
    "\n",
    "run_name = []\n",
    "\n",
    "b_acc_tuab = []\n",
    "b_acc_nmt = []\n",
    "b_acc_tueg = []\n",
    "\n",
    "ids_to_load_train = []\n",
    "ids_to_load_train2 = []\n",
    "ids_to_load_train3 = []\n",
    "\n",
    "for run in runs:\n",
    "    if run.state == 'finished': # NMT_deep4_hps_pp3_wN_wAug_WoPt81_28jul2045_index\n",
    "        if 'w11' in run.name: # or 'TUH_wZscore5min_w11_wAug_model_' in run.name:# or 'tuh_wzscore20min_n01_4B128_valNMT_model_' in run.name or 'tuh_wzscore5min_n01_4B128_valNMT_model_' in run.name:\n",
    "\n",
    "            try:\n",
    "                \n",
    "                if 'TUEGonlyNormal' in run.name or 'TUEGonlyAbNormal' in run.name:\n",
    "                    b_acc_tuab.append(NaN) \n",
    "                    b_acc_nmt.append(NaN) \n",
    "                    b_acc_tueg.append(NaN)\n",
    "                else:\n",
    "                    b_acc_tuab.append(run.summary['b_acc_tuh']) \n",
    "                    b_acc_nmt.append(run.summary['b_acc_nmt']) \n",
    "                    b_acc_tueg.append(run.summary['b_acc_tueg']) \n",
    "\n",
    "                ids_to_load_train.append(run.config[\"ids_to_load_train\"])\n",
    "                ids_to_load_train2.append(run.config[\"ids_to_load_train2\"])\n",
    "                ids_to_load_train3.append(run.config[\"ids_to_load_train3\"])\n",
    "\n",
    "                run_name.append(run.name) \n",
    "\n",
    "                \n",
    "\n",
    "            except:\n",
    "                print(run.name)\n",
    "                # run.delete()\n",
    "                \n",
    "df = pd.DataFrame({\n",
    "    'run_name':run_name,\n",
    "    'b_acc_tuab':b_acc_tuab,\n",
    "    'b_acc_nmt':b_acc_nmt,\n",
    "    'b_acc_tueg':b_acc_tueg,\n",
    "    'ids_to_load_train':ids_to_load_train,\n",
    "    'ids_to_load_train2':ids_to_load_train2,\n",
    "    'ids_to_load_train3':ids_to_load_train3       \n",
    "    })\n",
    "# df.head()\n",
    "df = df.assign(run_name_tranc = lambda x: x.run_name.str.split('_').str[0]) #+ '_' + str(x.pre_train))\n",
    "\n",
    "# import numpy as np\n",
    "# df[\"run_name_tranc_pretrain\"] = df[\"run_name_tranc\"] + \"_\" + np.where(df[\"pre_train\"], \"true\", \"false\")\n",
    "\n",
    "# df = df.assign(run_name_tranc = lambda x: str(x.pre_train))\n",
    "# df[\"ids_to_load_train\"] = df[\"ids_to_load_train\"].replace(0, 20)\n",
    "df.head(5)\n",
    "# df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "sns.set_palette(\"colorblind\")\n",
    "\n",
    "# Assuming df is your DataFrame and the columns are as you mentioned\n",
    "df_melted = df.melt(\n",
    "    id_vars=['run_name_tranc'],\n",
    "                     value_vars=['b_acc_tuab', 'b_acc_nmt', 'b_acc_tueg'],\n",
    "                       var_name='Category', value_name='test_acc')\n",
    "# df_melted = df_melted.melt(\n",
    "#             id_vars=['test_acc','Category'],\n",
    "#             value_vars=['ids_to_load_train', 'ids_to_load_train2', 'ids_to_load_train3'],\n",
    "#             var_name='ids_to_load_train', value_name='ids_to_load_train_name')\n",
    "# print(df_melted.head())\n",
    "\n",
    "# # Extract gender and condition from the Category\n",
    "# df_melted['Gender'] = df_melted['Category'].apply(lambda x: 'Female' if 'female' in x else 'Male')\n",
    "# df_melted['Condition'] = df_melted['Category'].apply(lambda x: 'Abnormal' if 'abnormal' in x else 'Normal')\n",
    "\n",
    "# # Now plot\n",
    "fig = sns.barplot(x='run_name_tranc', y='test_acc', data=df_melted, hue='Category',\n",
    "                  ci=68,\n",
    "                #    order=['TUHonlyNormal', 'NMTonlyNormal', 'TUEGonlyNormal'],\n",
    "                #   order=['TUHonlyAbNormal', 'NMTonlyAbNormal', 'TUEGonlyAbNormal'],\n",
    "                   order = ['TUHall','NMTall','TUEGall'],\n",
    "                 hue_order=['b_acc_tuab', 'b_acc_nmt', 'b_acc_tueg']\n",
    "                 \n",
    "                )\n",
    "\n",
    "\n",
    "\n",
    "fig.axes.set_yticklabels(fig.axes.get_yticks(), fontsize=24)\n",
    "# fig.axes.set_xticklabels(fig.axes.get_xticks(), fontsize=24)\n",
    "# fig.axes.set_xticklabels(None, fontsize=24)\n",
    "\n",
    "# define a custom function to format the labels\n",
    "def format_label(x, pos):\n",
    "    return f\"{x:.2f}\"\n",
    "\n",
    "\n",
    "# create a formatter object using the custom function\n",
    "formatter = FuncFormatter(format_label)\n",
    "\n",
    "# set the formatter for the y-axis\n",
    "fig.axes.yaxis.set_major_formatter(formatter)\n",
    "\n",
    "ax = plt.gca() # Get the current axes object\n",
    "# ax.set_xscale('log') # Set the y axis scale to log\n",
    "# ax.set_yscale('log') # Set the y axis scale to log\n",
    "plt.ylim([.48,.83])\n",
    "# plt.ylabel('Test Balanced Accuracy')\n",
    "# plt.xlabel('Number of Training Samples')\n",
    "\n",
    "plt.ylabel(None)\n",
    "plt.xlabel(None)\n",
    "fig.xaxis.set_ticklabels([])\n",
    "\n",
    "# plt.gca().legend().remove()\n",
    "\n",
    "# plt.savefig(\"../output/sex_onlyNormal_3ds_cb.svg\", format=\"svg\")\n",
    "# plt.savefig(\"../output/sex_onlyAbNormal_3ds_cb.svg\", format=\"svg\")\n",
    "# plt.savefig(\"../output/sex_all_3ds_cb_legends.svg\", format=\"svg\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sex detectability with more seedsusing wandb sweep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run wandb login on the command line and paste in your API key\n",
    "api = wandb.Api()\n",
    "# entity, project = \"mjavad\", \"tuh_sc_hps_pp3_cp_wN\"  \n",
    "entity, project, sweep_name = \"mjavad\", \"EEG_sex\" ,  \"u4826d3c\"\n",
    "\n",
    "runs = api.runs(entity + \"/\" + project)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import NaN\n",
    "\n",
    "\n",
    "all_runs = []\n",
    "model = []\n",
    "\n",
    "run_name = []\n",
    "\n",
    "b_acc_tuab = []\n",
    "b_acc_nmt = []\n",
    "b_acc_tueg = []\n",
    "\n",
    "ids_to_load_train = []\n",
    "ids_to_load_train2 = []\n",
    "ids_to_load_train3 = []\n",
    "train_ons = []\n",
    "pathology_split = []\n",
    "\n",
    "for run in runs:\n",
    "    if run.sweep is None or run.sweep.id != sweep_name:\n",
    "        continue\n",
    "    if run.state != \"finished\": # or run.config['r'] != r:\n",
    "        continue\n",
    "\n",
    "    # try:       \n",
    "    b_acc_tuab.append(run.summary['b_acc_tuh']) \n",
    "    b_acc_nmt.append(run.summary['b_acc_nmt']) \n",
    "    b_acc_tueg.append(run.summary['b_acc_tueg']) \n",
    "    \n",
    "\n",
    "    ids_to_load_train.append(run.config[\"ids_to_load_train\"])\n",
    "    ids_to_load_train2.append(run.config[\"ids_to_load_train2\"])\n",
    "    ids_to_load_train3.append(run.config[\"ids_to_load_train3\"])\n",
    "    pathology_split.append(run.config[\"pathology_split\"])\n",
    "    train_ons.append(run.config[\"train_on\"])\n",
    "\n",
    "    run_name.append(run.name) \n",
    "\n",
    "        # b_acc_tueg.append(run.summary['b_acc_tueg']) \n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "    # except:\n",
    "    #     print(run.name)\n",
    "    #     # run.delete()\n",
    "        \n",
    "df = pd.DataFrame({\n",
    "    'run_name':run_name,\n",
    "    'b_acc_tuab':b_acc_tuab,\n",
    "    'b_acc_nmt':b_acc_nmt,\n",
    "    'b_acc_tueg':b_acc_tueg,\n",
    "    'ids_to_load_train':ids_to_load_train,\n",
    "    'ids_to_load_train2':ids_to_load_train2,\n",
    "    'ids_to_load_train3':ids_to_load_train3,\n",
    "    'train_ons':train_ons,\n",
    "    'pathology_split':  pathology_split    \n",
    "    })\n",
    "# df.head()\n",
    "# df = df.assign(run_name_tranc = lambda x: x.run_name.str.split('_').str[0]) #+ '_' + str(x.pre_train))\n",
    "\n",
    "# import numpy as np\n",
    "# df[\"run_name_tranc_pretrain\"] = df[\"run_name_tranc\"] + \"_\" + np.where(df[\"pre_train\"], \"true\", \"false\")\n",
    "\n",
    "# df = df.assign(run_name_tranc = lambda x: str(x.pre_train))\n",
    "# df[\"ids_to_load_train\"] = df[\"ids_to_load_train\"].replace(0, 20)\n",
    "df.head(5)\n",
    "# df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from calendar import c\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "sns.set_palette(\"colorblind\")\n",
    "\n",
    "for cond in ['normal', 'abnormal', 'all']:\n",
    "\n",
    "  # Assuming df is your DataFrame and the columns are as you mentioned\n",
    "  df_melted = df[(df['pathology_split'] == cond)].melt(\n",
    "      id_vars=['train_ons'],\n",
    "                      value_vars=['b_acc_tuab', 'b_acc_nmt', 'b_acc_tueg'],\n",
    "                        var_name='Category', value_name='test_acc')\n",
    "  # # Now plot\n",
    "  fig = sns.barplot(x='train_ons', y='test_acc', data=df_melted, hue='Category',\n",
    "                    errorbar=('ci', 68),\n",
    "                  #    order=['TUHonlyNormal', 'NMTonlyNormal', 'TUEGonlyNormal'],\n",
    "                  #   order=['TUHonlyAbNormal', 'NMTonlyAbNormal', 'TUEGonlyAbNormal'],\n",
    "                    #  order = ['TUHall','NMTall','TUEGall'],\n",
    "                    order = ['only_TUAB','only_NMT', 'only_TUEG'],\n",
    "                  hue_order=['b_acc_tuab', 'b_acc_nmt', 'b_acc_tueg']\n",
    "                  \n",
    "                  )\n",
    "\n",
    "  fig.axes.set_yticklabels(fig.axes.get_yticks(), fontsize=24)\n",
    "  # fig.axes.set_xticklabels(fig.axes.get_xticks(), fontsize=24)\n",
    "  # fig.axes.set_xticklabels(None, fontsize=24)\n",
    "\n",
    "  # define a custom function to format the labels\n",
    "  def format_label(x, pos):\n",
    "      return f\"{x:.2f}\"\n",
    "\n",
    "\n",
    "  # create a formatter object using the custom function\n",
    "  formatter = FuncFormatter(format_label)\n",
    "\n",
    "  # set the formatter for the y-axis\n",
    "  fig.axes.yaxis.set_major_formatter(formatter)\n",
    "\n",
    "  ax = plt.gca() # Get the current axes object\n",
    "  # ax.set_xscale('log') # Set the y axis scale to log\n",
    "  # ax.set_yscale('log') # Set the y axis scale to log\n",
    "  plt.ylim([.48,.83])\n",
    "  # plt.ylabel('Test Balanced Accuracy')\n",
    "  # plt.xlabel('Number of Training Samples')\n",
    "\n",
    "  plt.ylabel(None)\n",
    "  plt.xlabel(None)\n",
    "  fig.xaxis.set_ticklabels([])\n",
    "\n",
    "  plt.show()\n",
    "  # plt.gca().legend().remove()\n",
    "\n",
    "  # plt.savefig(\"../output/sex_onlyNormal_3ds_cb.svg\", format=\"svg\")\n",
    "  # plt.savefig(\"../output/sex_onlyAbNormal_3ds_cb.svg\", format=\"svg\")\n",
    "  # plt.savefig(\"../output/sex_all_3ds_cb_legends.svg\", format=\"svg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Appendix\n",
    ":P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['Model', 'ids_to_load_train2']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['Model']=='Deep4Net'].groupby(['ids_to_load_train']).std().sort_values(by='test_b_acc', ascending=False).head(20)\n",
    "# df[df['Model']=='TCN'].sort_values(by='test_b_acc', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['Model']=='TCN'].sort_values(by='test_b_acc', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run = runs[-2]\n",
    "df[df[\"ids_to_load_train2\"]==0]\n",
    "df.plot(x=\"ids_to_load_train2\", y=\"test_b_acc\", kind=\"scatter\")\n",
    "plt.xlim(0, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[df[\"ids_to_load_train2\"]][\"ids_to_load_train2\"]=1\n",
    "df[\"ids_to_load_train2\"] = df[\"ids_to_load_train2\"].replace(0, 1)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.summary.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_to_load_train"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
